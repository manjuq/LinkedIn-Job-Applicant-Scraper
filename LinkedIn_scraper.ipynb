{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException \n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the user to input their LinkedIn username and password\n",
    "USERNAME = input(\"Enter your LinkedIn username: \")\n",
    "PASSWORD = input(\"Enter your LinkedIn password: \")\n",
    "\n",
    "# Set up the Selenium WebDriver using ChromeDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://linkedin.com/uas/login\")  # Open LinkedIn login page\n",
    "\n",
    "# Find and fill in the username field\n",
    "username_field = driver.find_element(By.ID, \"username\")\n",
    "username_field.send_keys(USERNAME)\n",
    "# Find and fill in the password field\n",
    "password_field = driver.find_element(By.ID, \"password\")\n",
    "password_field.send_keys(PASSWORD)\n",
    "\n",
    "# Click on the sign-in button\n",
    "sign_in_btn = driver.find_element(By.CSS_SELECTOR, \"button[type='submit']\")\n",
    "sign_in_btn.click()\n",
    "driver.maximize_window()  # Maximize the browser window for better visibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sign-in button clicked successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the Selenium WebDriver using ChromeDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://linkedin.com/uas/login\")  # Open LinkedIn login page\n",
    "\n",
    "# Find and fill in the username field\n",
    "username_field = driver.find_element(By.ID, \"username\")\n",
    "username_field.send_keys(USERNAME)\n",
    "\n",
    "# Find and fill in the password field\n",
    "password_field = driver.find_element(By.ID, \"password\")\n",
    "password_field.send_keys(PASSWORD)\n",
    "\n",
    "# Click on the sign-in button\n",
    "sign_in_btn = driver.find_element(By.CSS_SELECTOR, \"button[type='submit']\")\n",
    "sign_in_btn.click()\n",
    "\n",
    "# Assuming the click was successful if no exception is raised\n",
    "print(\"Sign-in button clicked successfully\")\n",
    "\n",
    "driver.maximize_window()  # Maximize the browser window for better visibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Job postings button clicked successfully\n"
     ]
    }
   ],
   "source": [
    "# Define the profile URL to scrape\n",
    "profile_url = \"https://www.linkedin.com/my-items/posted-jobs/?jobState=CLOSED\"\n",
    "driver.get(profile_url)  # Open the profile URL\n",
    "print(\"Closed Job postings button clicked successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Assistant job position opened successfully\n"
     ]
    }
   ],
   "source": [
    "# Find the link for a specific job\n",
    "link = driver.find_element(By.XPATH, '//a[@href=\"https://www.linkedin.com/hiring/jobs/3673652843/detail/\"]')\n",
    "link.click()  # Click on the job link\n",
    "print(\"Research Assistant job position opened successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View applicants button clicked successfully\n"
     ]
    }
   ],
   "source": [
    "# Click on the 'View applicants' button\n",
    "span_element = driver.find_element(By.XPATH, '//span[text()=\"View applicants\"]')\n",
    "span_element.click()\n",
    "print(\"View applicants button clicked successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages for this job application are 70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a new BeautifulSoup object with updated page source\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "# Extract the number of pages from pagination\n",
    "spans = soup.select('ul.artdeco-pagination__pages--number span')\n",
    "total_pages = int(spans[-1].text)\n",
    "print(f'Total pages for this job application are {total_pages}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/hiring/jobs/3673652843/applicants/19205269753/detail/?r=UNRATED%2CGOOD_FIT%2CMAYBE&start=0\n",
      "Name: Sumana ********\n",
      "Email: ************ya@gmail.com\n",
      "Mobile: +91720*******\n",
      "Location: Hyderabad, Telangana, India\n",
      "Current title: PHD Scholar\n",
      "Current Company: Gandhi Institute of Technology & Management (GITAM) University, Visakhapatnam\n",
      "LinkedIn_URL: https://www.linkedin.com//in/sumana-moun***************\n",
      "Name: Khushb******\n",
      "Email: ***********u@gmail.com\n",
      "Mobile: +91623*******\n",
      "Location: Jalandhar, Punjab, India\n",
      "Current title: Team Lead\n",
      "Current Company: GravEiens Edu Services Pvt. Ltd.\n",
      "LinkedIn_URL: https://www.linkedin.com//i***************\n",
      "Name: Chetan******\n",
      "Email: ***********u@gmail.com\n",
      "Mobile: +91623*******\n",
      "Location: Jalandhar, Punjab, India\n",
      "Current title: Team Lead\n",
      "Current Company: GravEiens Edu Services Pvt. Ltd.\n",
      "LinkedIn_URL: https://www.linkedin.com//i***************\n",
      "Name: Arpa G******\n",
      "Email: ************23@gmail.com\n",
      "Mobile: +91750*******\n",
      "Location: Gurugram, Haryana, India\n",
      "Current title: Associate Scientist\n",
      "Current Company: Syngene International Limited\n",
      "LinkedIn_URL: https://www.linkedin.com//***************\n",
      "https://www.linkedin.com/hiring/jobs/3673652843/applicants/15645020836/detail/?r=UNRATED%2CGOOD_FIT%2CMAYBE&start=25\n",
      "Name: CHETHAN********\n",
      "Email: **********@gmail.com\n",
      "Mobile: +91974*******\n",
      "Location: Bengaluru, Karnataka, India\n",
      "Current title: Insurance Analyst\n",
      "Current Company: EOX Vantage\n",
      "LinkedIn_URL: https://www.linkedin.com//in/chethan-nag***************\n",
      "Name: Brin*****\n",
      "Email: ************01@gmail.com\n",
      "Mobile: +91994*******\n",
      "Location: Salem, Tamil Nadu, India\n",
      "Current title: Python Developer\n",
      "Current Company: Python Trainee at Besant technology\n",
      "LinkedIn_URL: https://www.linkedin.com//in/brind***************\n",
      "Name: Himans*******\n",
      "Email: *************816@gmail.com\n",
      "Mobile: +91773*******\n",
      "Location: Mumbai, Maharashtra, India\n",
      "Current title: Content Creator / E-Commerce Head\n",
      "Current Company: Abuggys Private Limited\n",
      "LinkedIn_URL: https://www.linkedin.com//in/himanshi***************\n",
      "Name: Mayank *******\n",
      "Email: *********gmail.com\n",
      "Mobile: +91701*******\n",
      "Location: Jodhpur, Rajasthan, India\n",
      "Current title: Microbiology Officer\n",
      "Current Company: Troikaa Pharmaceuticals Ltd.\n",
      "LinkedIn_URL: https://www.linkedin.com//in/mayank-dau***************\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "applicants_info = []\n",
    "\n",
    "# Loop through each page of applicants\n",
    "for i in range(2):\n",
    "    current_url = f\"{driver.current_url}&start={i * 25}\"  # Update URL with pagination\n",
    "    print(current_url)\n",
    "    driver.get(current_url)\n",
    "    time.sleep(1)\n",
    "    # Loop through each applicant on the page\n",
    "    for j in range(1, 5):\n",
    "        xpath = f\"/html/body/div[4]/div[3]/div/div[3]/div/div/div[2]/ul/li[{j}]\"\n",
    "        try:\n",
    "            link_element = driver.find_element(By.XPATH, xpath)\n",
    "            link_element.click()\n",
    "        except NoSuchElementException:\n",
    "            print('No element found')\n",
    "            continue\n",
    "        if xpath:\n",
    "            try:\n",
    "                name = driver.find_element(By.XPATH, f\"/html/body/div[4]/div[3]/div/div[3]/div/div/div[2]/ul/li[{j}]/a/div/div[2]/div[1]\").text\n",
    "            except NoSuchElementException:\n",
    "                name = None\n",
    "            time.sleep(1)\n",
    "            # Extract applicant information\n",
    "            try:\n",
    "                current_title = driver.find_element(By.XPATH, '/html/body/div[4]/div[3]/div/div[3]/div/main/div/div[2]/div[1]/section[1]/ul/li[1]/div/p[1]').text\n",
    "            except NoSuchElementException:\n",
    "                current_title = None\n",
    "            try:\n",
    "                current_company = driver.find_element(By.XPATH, '/html/body/div[4]/div[3]/div/div[3]/div/main/div/div[2]/div[1]/section[1]/ul/li[1]/div/p[2]').text\n",
    "            except NoSuchElementException:\n",
    "                current_company = None\n",
    "            try:\n",
    "                location = driver.find_element(By.XPATH, f'/html/body/div[4]/div[3]/div/div[3]/div/main/div/div[1]/div[1]/div[1]/div[1]/div[2]').text\n",
    "            except NoSuchElementException:\n",
    "                location = None\n",
    "\n",
    "            # Click on 'More' button to reveal additional applicant information\n",
    "            more_button = WebDriverWait(driver, 2.5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '/html/body/div[4]/div[3]/div/div[3]/div/main/div/div[1]/div[1]/div[1]/div[2]/div[3]'))\n",
    "            )\n",
    "            more_button.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Create a new BeautifulSoup object to parse updated page source\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            results = soup.find_all('span', {'class': 'hiring-applicant-header-actions__more-content-dropdown-item-text'})\n",
    "            time.sleep(1)\n",
    "            # Extract LinkedIn URL\n",
    "            try:\n",
    "                linkedin = soup.find('div', class_='artdeco-dropdown__item artdeco-dropdown__item--is-dropdown ember-view p0').find('a').get('href')\n",
    "                linked_url = 'https://www.linkedin.com/' + linkedin\n",
    "            except AttributeError:\n",
    "                linked_url = None\n",
    "            time.sleep(1)\n",
    "            # Extract resume link\n",
    "            try:\n",
    "                div_element = soup.find('div', class_='display-flex justify-space-between align-items-flex-start pl5 pr5 pt5 pb3')\n",
    "                if div_element is None:\n",
    "                    div_element = soup.find('div', class_='ui-attachment ui-attachment--doc')\n",
    "                if div_element:\n",
    "                    resume_link = div_element.find('a').get('href')\n",
    "            except AttributeError:\n",
    "                resume_link = None\n",
    "            # Extract email and mobile number\n",
    "            try: \n",
    "                email, mob = [r.text.replace('\\n', '').replace(' ', '') for r in results]\n",
    "            except ValueError:\n",
    "                email = None\n",
    "                mob =  None\n",
    "\n",
    "            # Append applicant information to the list\n",
    "            info = {'Name': name, 'Email': email, 'Mobile': mob,\n",
    "                    'Location': location, \"Current title\": \n",
    "                    current_title,'Current Company': current_company,\n",
    "                    'LinkedIn_URL': linked_url, 'Resume_Link': resume_link}\n",
    "            \n",
    "            #Masked email and phone\n",
    "            masked_name = name[:len(name)//2] + '*' * (len(name) - len(name)//2)\n",
    "            masked_email = '*' * (len(email) - len(email)//2) + email[len(email)//2:]\n",
    "            masked_phone = mob[:len(mob)//2] + '*' * (len(mob) - len(mob)//2)\n",
    "            masked_linked_url = linked_url[:len(linked_url)-15] + '*' * (15)\n",
    "\n",
    "            #Print Job applicant info\n",
    "            print(f\"Name: {masked_name}\\nEmail: {masked_email}\\nMobile: {masked_phone}\\nLocation: {location}\\nCurrent title: {current_title}\\nCurrent Company: {current_company}\\nLinkedIn_URL: {masked_linked_url}\")\n",
    "\n",
    "            applicants_info.append(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the collected applicant information\n",
    "applicants_df = pd.DataFrame(applicants_info)\n",
    "\n",
    "# Save DataFrame to an Excel file\n",
    "applicants_df.to_excel('job_applicants.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
